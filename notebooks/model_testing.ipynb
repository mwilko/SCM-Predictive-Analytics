{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tensorflow.keras.models\n",
    "%pip install tensorflow.keras.layers\n",
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np, pandas as pd, seaborn as sb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# NN imports\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "# ensemble \n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets and transformations (reusability purposes)\n",
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().run_line_magic('run', 'datasets.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â # COULD BE USED FOR FEATURE ENGINEERING\n",
    "\n",
    "# # Ensure 'OrderDate' and 'Ship_by_Date' are in datetime format\n",
    "# merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'])\n",
    "# merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'])\n",
    "\n",
    "# # 'Lead_Time' in days\n",
    "# merged_data['Lead_Time'] = (merged_data['Ship_by_Date'] - merged_data['OrderDate']).dt.days\n",
    "# # missing values in 'Lead_Time'\n",
    "# merged_data['Lead_Time'].fillna(merged_data['Lead_Time'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and paramgrids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from model_utils import * # evaluate_model, param grids and hyperparm tuning\n",
    "\n",
    "# define the features and target variable from 'product_sales'\n",
    "X = product_sales[['ProductNumber', 'order_month']]\n",
    "y = product_sales['OrderQuantity']\n",
    "\n",
    "# convert 'ProductNumber' to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "X['ProductNumber'] = label_encoder.fit_transform(X['ProductNumber'])\n",
    "\n",
    "# normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train-test split with scaled features\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with scaled features (Random Forest Regressor)\n",
    "rf = RandomForestRegressor()\n",
    "rf_params = find_best_hyperparameters(rf, param_grids(rf.__class__.__name__), X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(**rf_params)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf, X_scaled, y)\n",
    "print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model with scaled features (Decision Tree Regressor)\n",
    "# dt = DecisionTreeRegressor()\n",
    "# dt_params = find_best_hyperparameters(dt, param_grids(dt), X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = DecisionTreeRegressor(**dt_params)\n",
    "# dt.fit(X_train_scaled, y_train)\n",
    "# y_pred_dt = dt.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(dt, X_scaled, y)\n",
    "# print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model with scaled features (Linear Regression)\n",
    "# lr = LinearRegression()\n",
    "# lr_params = find_best_hyperparameters(lr, param_grids(lr), X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression(**lr_params)\n",
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_pred_lr = lr.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(lr, X_scaled, y)\n",
    "# print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN METRICS ARE NOT ARENT BETTER THAN BASE MODELS, SO ITS COMMENTED OUT\n",
    "\n",
    "# Define the neural network model\n",
    "def create_nn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_shape, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model with KerasRegressor\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "nn_model = KerasRegressor(build_fn=create_nn_model, input_shape=input_shape, verbose=1)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=nn_model, param_grid=param_grids(nn_model.__class__.__name__), cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "nn_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {nn_params}')\n",
    "\n",
    "# Set the best parameters to the model\n",
    "nn_model.set_params(**nn_params)\n",
    "\n",
    "# Use cross_val_score or other scikit-learn utilities\n",
    "scores = cross_val_score(nn_model, X_train_scaled, y_train, cv=5)\n",
    "print(scores)\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(X_train_scaled, y_train, epochs=nn_params['epochs'], batch_size=nn_params['batch_size'], validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict using the neural network model\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(nn_model, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(nn_model, X_scaled, y)\n",
    "print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "# Plot the bar plot to compare the actual and predicted values\n",
    "axes[0].bar(product_sales.loc[y_val.index, 'ProductNumber'], y_val, label='Actual', alpha=0.6)\n",
    "axes[0].bar(product_sales.loc[y_val.index, 'ProductNumber'], y_pred_rf, label='Predicted', alpha=0.6)\n",
    "axes[0].set_xlabel('Product Number')\n",
    "axes[0].set_ylabel('Order Quantity')\n",
    "axes[0].set_title('Actual vs Predicted Order Quantity')\n",
    "axes[0].set_ylim(0, 2250000)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot the residual plot\n",
    "residuals = y_val - y_pred_rf\n",
    "axes[1].scatter(product_sales.loc[y_val.index, 'ProductNumber'], residuals, alpha=0.6)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Product Number')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_rf = BaggingRegressor(estimator=RandomForestRegressor(**rf_params), n_estimators=10, random_state=42)\n",
    "bagging_rf.fit(X_train_scaled, y_train)\n",
    "y_pred_bagging_rf = bagging_rf.predict(X_val_scaled)\n",
    "\n",
    "evaluate_model(bagging_rf, X_scaled, y)\n",
    "print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging_nn = BaggingRegressor(estimator=KerasRegressor(build_fn=create_nn_model, input_shape=input_shape, **nn_params), n_estimators=10, random_state=42)\n",
    "# bagging_nn.fit(X_train_scaled, y_train)\n",
    "# y_pred_bagging_nn = bagging_nn.predict(X_val_scaled)\n",
    "\n",
    "# evaluate_model(bagging_nn, X_scaled, y)\n",
    "# print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Bagging: \n",
    "Mean Absolute Error (MAE): 145788.9249\n",
    "Mean Squared Error (MSE): 117073044061.8419\n",
    "Root Mean Squared Error (RMSE): 342159.3840\n",
    "R-squared (RÂ²): 0.0013\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "rf_nn_voting = VotingRegressor(estimators=[('rf', RandomForestRegressor(**rf_params)), ('nn', KerasRegressor(build_fn=create_nn_model, input_shape=input_shape, **nn_params))])\n",
    "rf_nn_voting.fit(X_train_scaled, y_train)\n",
    "y_pred_rf_nn_voting = rf_nn_voting.predict(X_val_scaled)\n",
    "\n",
    "evaluate_model(rf_nn_voting, X_scaled, y)\n",
    "print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Ensemble\n",
    "\n",
    "Mean Absolute Error (MAE): 134711.8210\n",
    "Mean Squared Error (MSE): 116899234027.1837\n",
    "Root Mean Squared Error (RMSE): 341905.2998\n",
    "R-squared (RÂ²): 0.0028\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "# Plot the bar plot to compare the actual and predicted values\n",
    "axes[0].bar(product_sales.loc[y_val.index, 'ProductNumber'], y_val, label='Actual', alpha=0.6)\n",
    "axes[0].bar(product_sales.loc[y_val.index, 'ProductNumber'], y_pred_rf_nn_voting, label='Predicted', alpha=0.6)\n",
    "axes[0].set_xlabel('Product Number')\n",
    "axes[0].set_ylabel('Order Quantity')\n",
    "axes[0].set_title('Actual vs Predicted Order Quantity')\n",
    "axes[0].set_ylim(0, 2250000)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot the residual plot\n",
    "residuals = y_val - y_pred_rf_nn_voting\n",
    "axes[1].scatter(product_sales.loc[y_val.index, 'ProductNumber'], residuals, alpha=0.6)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Product Number')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
