{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProductHandler \u001b[38;5;28;01mas\u001b[39;00m ph\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_config'"
     ]
    }
   ],
   "source": [
    "from data_config import ProductHandler as ph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph.custom_prod_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define the features and target variable from 'product_sales'\n",
    "# CHANGE THE CUSTOMER CODE HERE >>>>>>>>>>\n",
    "custom_code_df = pd.DataFrame(ph.get_custom_code_data('UND'))\n",
    "\n",
    "# customer code for later referencing\n",
    "custom_ref = custom_code_df.loc[0, 'ProductNumber'][:3].lower().upper()\n",
    "print(custom_ref)\n",
    "\n",
    "custom_code_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Define a function to compute z-scores within each product group\n",
    "def compute_zscore(group, threshold=3):\n",
    "    # Only compute z-score if there are at least 2 data points in the group\n",
    "    if len(group) >= 2:\n",
    "        group['z_score'] = np.abs(stats.zscore(group['OrderQuantity']))\n",
    "    else:\n",
    "        group['z_score'] = 0  # or np.nan if preferred\n",
    "    return group\n",
    "\n",
    "# Group by \"ProductNumber\" and compute z-scores for \"OrderQuantity\" within each group\n",
    "df_grouped = custom_code_df.groupby('ProductNumber').apply(compute_zscore)\n",
    "\n",
    "# Define your threshold for what constitutes an \"unusually high\" order\n",
    "z_threshold = 3\n",
    "\n",
    "# Filter for outliers (orders with a z_score greater than the threshold)\n",
    "df_outliers = df_grouped[df_grouped['z_score'] > z_threshold]\n",
    "\n",
    "# Display the results\n",
    "print(\"Unusually high order quantities (per ProductNumber):\")\n",
    "print(df_outliers[['ProductNumber', 'OrderQuantity', 'z_score']])\n",
    "\n",
    "print(f'Dropping: \\n{df_outliers.count()}')\n",
    "# Keep only rows where the z-score is within the acceptable range\n",
    "df_cleaned = df_grouped[df_grouped['z_score'] <= z_threshold].drop(columns=['z_score'])\n",
    "\n",
    "# Reset index for clarity\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "custom_code_df = df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "df = custom_code_df\n",
    "\n",
    "features = ['ProductNumber', 'order_month',\n",
    "            'prev_month_sales', 'prev_week_sales', 'prev_2_month_sales', 'prev_3_month_sales',\n",
    "            'moving_avg_3m', 'moving_avg_6m', 'moving_avg_12m', 'moving_avg_18m',\n",
    "            'var_3m', 'var_6m', 'var_12m', 'var_18m',\n",
    "            'log_var_3m', 'log_var_6m', 'log_var_12m', 'log_var_18m',\n",
    "            'yoy_growth', 'sales_2023', 'sales_2024'\n",
    "            ]\n",
    "target = 'OrderQuantity'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# one-hot encoding for categorical features\n",
    "categorical_features = ['ProductNumber']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# preprocessor (keeps numerical features as is)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # one-hot encode categorical features\n",
    "        ('cat', encoder, categorical_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# transform the features\n",
    "X_transformed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset\n",
    "customer_total = df.copy()\n",
    "\n",
    "# Define features and target\n",
    "features = ['ProductNumber', 'order_month', 'order_week', 'order_weekday',\n",
    "            'prev_month_sales', 'prev_week_sales', 'prev_2_month_sales', 'prev_3_month_sales',\n",
    "            'moving_avg_3m', 'moving_avg_6m', 'moving_avg_12m', 'moving_avg_18m',\n",
    "            'var_3m', 'var_6m', 'var_12m', 'var_18m',\n",
    "            'log_var_3m', 'log_var_6m', 'log_var_12m', 'log_var_18m',\n",
    "            'yoy_growth', 'sales_2023', 'sales_2024']\n",
    "target = 'OrderQuantity'\n",
    "\n",
    "# Filter the top products\n",
    "total_X = customer_total[features]  # Features\n",
    "total_y = customer_total[target]    # Target\n",
    "\n",
    "# Define categorical and numeric features\n",
    "categorical_features = ['ProductNumber']\n",
    "numeric_features = list(set(features) - set(categorical_features))\n",
    "\n",
    "# Define transformations\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ColumnTransformer to apply transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', encoder, categorical_features),\n",
    "        ('num', scaler, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "total_X_train, total_X_val, total_y_train, total_y_val = train_test_split(total_X, total_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the features\n",
    "total_X_train_transformed = preprocessor.fit_transform(total_X_train)\n",
    "total_X_val_transformed = preprocessor.transform(total_X_val)\n",
    "\n",
    "# Define Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(total_X_train_transformed.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(total_X_train_transformed, total_y_train, \n",
    "                    validation_data=(total_X_val_transformed, total_y_val),\n",
    "                    epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Make Predictions\n",
    "total_y_pred = model.predict(total_X_val_transformed)\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = total_X_val.copy()\n",
    "predictions_df['Actual_OrderQuantity'] = total_y_val\n",
    "predictions_df['Predicted_OrderQuantity'] = total_y_pred\n",
    "\n",
    "# Plot Actual vs. Predicted Values\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=predictions_df['Actual_OrderQuantity'], y=predictions_df['Predicted_OrderQuantity'], alpha=0.6)\n",
    "plt.plot([predictions_df['Actual_OrderQuantity'].min(), predictions_df['Actual_OrderQuantity'].max()], \n",
    "         [predictions_df['Actual_OrderQuantity'].min(), predictions_df['Actual_OrderQuantity'].max()], \n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "plt.xlabel(\"Actual Order Quantity\")\n",
    "plt.ylabel(\"Predicted Order Quantity\")\n",
    "plt.title(\"Actual vs. Predicted Order Quantity\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Neural Network model training and evaluation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
