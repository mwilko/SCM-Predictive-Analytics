{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset initialization and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/2542517297.py:4: DtypeWarning: Columns (4,6,20,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  products_s = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Products [STOCK].txt', sep='\\t', header=0) # stock\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/2542517297.py:5: DtypeWarning: Columns (5,29,42,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tickets_c_i = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Tickets [CUSTOM] [ITEMS].txt', sep='\\t', header=0) # customer order items\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/2542517297.py:6: DtypeWarning: Columns (43,57,106,141,146,211,212,247,255,294,298,316,327,332,350,354) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tickets_c_m = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Tickets [CUSTOM] [MAIN].txt', sep='\\t', header=0) # customer order main data\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/2542517297.py:7: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sp_inv_adds = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] SP Inventory [ADDS].txt', sep='\\t', header=0) # customer order main data\n"
     ]
    }
   ],
   "source": [
    "# convert datasets to csv from txt\n",
    "\n",
    "# \\t used as separator, because of raw data format and the headers as row 0\n",
    "products_s = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Products [STOCK].txt', sep='\\t', header=0) # stock\n",
    "tickets_c_i = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Tickets [CUSTOM] [ITEMS].txt', sep='\\t', header=0) # customer order items\n",
    "tickets_c_m = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] Tickets [CUSTOM] [MAIN].txt', sep='\\t', header=0) # customer order main data\n",
    "sp_inv_adds = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] SP Inventory [ADDS].txt', sep='\\t', header=0) # customer order main data\n",
    "sp_inv_rel = pd.read_csv('../datasets/stock_forecasting/raw/2022-2025/[LT] SP Inventory [REL].txt', sep='\\t', header=0) # customer order main data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Product [STOCK] ----------------\n",
      "   Adhesive  Alternate  Available  BackOrdered Box_Size  CaseQty Color  \\\n",
      "0       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "1       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "2       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "3       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "4       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "\n",
      "   Commission   Cost  Currency_ExchangeRate  ...  SupplierName  SupplierNo  \\\n",
      "0           0   0.00                      0  ...           NaN         NaN   \n",
      "1           0   0.00                      0  ...           NaN         NaN   \n",
      "2           0   0.00                      0  ...           NaN         NaN   \n",
      "3           0   0.00                      0  ...           NaN         NaN   \n",
      "4           0  49.11                      0  ...           NaN         NaN   \n",
      "\n",
      "  SupplierNotes SupplierPartNo Tag TotalCost UPC   Updated  \\\n",
      "0           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "1           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "2           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "3           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "4           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "\n",
      "        updateTimeDateStamp  Weight  \n",
      "0  2024-11-12T18:44:36.831Z       0  \n",
      "1  2024-11-12T18:59:23.570Z       0  \n",
      "2  2024-11-12T18:44:36.849Z       0  \n",
      "3  2024-11-12T18:44:36.879Z       0  \n",
      "4  2024-11-12T18:48:39.525Z       0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "-------------- Tickets [CUSTOM] [ITEMS] ----------------\n",
      "     Art  Art_Item  Art_Ticket  Assigned                        ColorDescr  \\\n",
      "0  False     False       False       NaN         C: WHITE, CMYOK, LAM ADH    \n",
      "1  False     False       False       NaN              C: MYK, GLOSS 54121    \n",
      "2  False     False       False       NaN  C: CMYK,7512C,363C,286C,LAM ADH    \n",
      "3  False     False       False       NaN  C: CMYK,7512C,363C,286C,LAM ADH    \n",
      "4  False     False       False       NaN                C: CMYK, GLOSS V     \n",
      "\n",
      "  ConsecNo  CostM  Desc2                                   Description  \\\n",
      "0      NaN      0    NaN            510016W Gumout All In One FSC 10oz   \n",
      "1      NaN      0    NaN       510022W Gumout Octane Booster 10oz Wrap   \n",
      "2      NaN      0    NaN   Simply Nature 93/7 Ground Beef Famil Pack B   \n",
      "3      NaN      0    NaN  Simply Nature 93/7 Ground Beef Family Pack F   \n",
      "4      NaN      0    NaN      72969 FL Ginger Sweet Chili Sauce 14.5oz   \n",
      "\n",
      "   ediLineNumber  ...  Proof_Out  Proof_Ticket  StckPrdShipStat  \\\n",
      "0            NaN  ...   00/00/00         False              NaN   \n",
      "1            NaN  ...   00/00/00         False              NaN   \n",
      "2            NaN  ...   00/00/00         False              NaN   \n",
      "3            NaN  ...   00/00/00         False              NaN   \n",
      "4            NaN  ...   00/00/00         False              NaN   \n",
      "\n",
      "   StockProductID  TicketNumber  UniquePrice  UniqueProdID  Unit_Weight  \\\n",
      "0             NaN         99999        False       11704.0            0   \n",
      "1             NaN         99997        False        7728.0            0   \n",
      "2             NaN         99996        False       28747.0            0   \n",
      "3             NaN         99995        False       28746.0            0   \n",
      "4             NaN         99993        False       10474.0            0   \n",
      "\n",
      "        updateTimeDateStamp   Work_Status  \n",
      "0  2025-01-21T10:00:53.048Z           NaN  \n",
      "1  2025-01-21T09:59:44.079Z           NaN  \n",
      "2  2025-01-20T20:26:55.057Z      Inactive  \n",
      "3  2024-11-13T17:45:49.909Z  8. In Plates  \n",
      "4  2025-02-05T17:57:16.910Z           NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "-------------- Tickets [CUSTOM] [MAIN] ----------------\n",
      "   Act_MakeReady_Footage  Act_OTHER_Hours  ActArtwork  ActFinMaterial  \\\n",
      "0                      0                0           0               0   \n",
      "1                      0                0           0               0   \n",
      "2                      0                0           0               0   \n",
      "3                      0                0           0               0   \n",
      "4                      0                0           0               0   \n",
      "\n",
      "   ActFootage  ActMRHrs  ActPackHrs  ActPostPressHours  ActPressSpd  \\\n",
      "0           0       0.0           0                  0            0   \n",
      "1           0       0.0           0                  0            0   \n",
      "2           0       0.0           0                  0            0   \n",
      "3           0       0.0           0                  0            0   \n",
      "4           0       0.0           0                  0            0   \n",
      "\n",
      "   ActQuantity  ...  TotalOrderWeight  TotalShipWeight  TurnBar     UL  \\\n",
      "0            0  ...                 0                0    False  False   \n",
      "1            0  ...                 0                0    False  False   \n",
      "2            0  ...                 0                0    False  False   \n",
      "3            0  ...                 0                0    False  False   \n",
      "4            0  ...                 0                0    False  False   \n",
      "\n",
      "        updateTimeDateStamp  Use_TurretRewinder  UserDef_MR_1  \\\n",
      "0  2025-02-18T13:13:14.001Z               False         False   \n",
      "1  2025-02-18T13:10:42.128Z               False         False   \n",
      "2  2025-02-18T09:59:34.975Z               False         False   \n",
      "3  2025-02-17T22:32:37.678Z               False         False   \n",
      "4  2025-02-17T22:31:37.158Z               False         False   \n",
      "\n",
      "   UserDef_MR_1_Lb  UserDef_MR_2  UserDef_MR_2_Lb  \n",
      "0              NaN         False              NaN  \n",
      "1              NaN         False              NaN  \n",
      "2              NaN         False              NaN  \n",
      "3              NaN         False              NaN  \n",
      "4              NaN         False              NaN  \n",
      "\n",
      "[5 rows x 371 columns]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# display the first 5 rows of the datasets\n",
    "print('-------------- Product [STOCK] ----------------')\n",
    "print(products_s.head())\n",
    "\n",
    "print('-------------- Tickets [CUSTOM] [ITEMS] ----------------')\n",
    "print(tickets_c_i.head())\n",
    "\n",
    "print('-------------- Tickets [CUSTOM] [MAIN] ----------------')\n",
    "print(tickets_c_m.head())\n",
    "print('------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change product stock column 'ProductNo' to 'ProductNumber' to match the other datasets\n",
    "products_s.rename(columns={'ProductNo': 'ProductNumber'}, inplace=True)\n",
    "\n",
    "# change the column name of 'Number' to 'TicketNumber'\n",
    "tickets_c_m.rename(columns={'Number': 'TicketNumber'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act_MakeReady_Footage</th>\n",
       "      <th>Act_OTHER_Hours</th>\n",
       "      <th>ActArtwork</th>\n",
       "      <th>ActFinMaterial</th>\n",
       "      <th>ActFootage</th>\n",
       "      <th>ActMRHrs</th>\n",
       "      <th>ActPackHrs</th>\n",
       "      <th>ActPostPressHours</th>\n",
       "      <th>ActPressSpd</th>\n",
       "      <th>ActQuantity</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalOrderWeight</th>\n",
       "      <th>TotalShipWeight</th>\n",
       "      <th>TurnBar</th>\n",
       "      <th>UL</th>\n",
       "      <th>updateTimeDateStamp</th>\n",
       "      <th>Use_TurretRewinder</th>\n",
       "      <th>UserDef_MR_1</th>\n",
       "      <th>UserDef_MR_1_Lb</th>\n",
       "      <th>UserDef_MR_2</th>\n",
       "      <th>UserDef_MR_2_Lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-18T13:13:14.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-18T13:10:42.128Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-18T09:59:34.975Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-17T22:32:37.678Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-17T22:31:37.158Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Act_MakeReady_Footage  Act_OTHER_Hours  ActArtwork  ActFinMaterial  \\\n",
       "0                      0                0           0               0   \n",
       "1                      0                0           0               0   \n",
       "2                      0                0           0               0   \n",
       "3                      0                0           0               0   \n",
       "4                      0                0           0               0   \n",
       "\n",
       "   ActFootage  ActMRHrs  ActPackHrs  ActPostPressHours  ActPressSpd  \\\n",
       "0           0       0.0           0                  0            0   \n",
       "1           0       0.0           0                  0            0   \n",
       "2           0       0.0           0                  0            0   \n",
       "3           0       0.0           0                  0            0   \n",
       "4           0       0.0           0                  0            0   \n",
       "\n",
       "   ActQuantity  ...  TotalOrderWeight  TotalShipWeight  TurnBar     UL  \\\n",
       "0            0  ...                 0                0    False  False   \n",
       "1            0  ...                 0                0    False  False   \n",
       "2            0  ...                 0                0    False  False   \n",
       "3            0  ...                 0                0    False  False   \n",
       "4            0  ...                 0                0    False  False   \n",
       "\n",
       "        updateTimeDateStamp  Use_TurretRewinder  UserDef_MR_1  \\\n",
       "0  2025-02-18T13:13:14.001Z               False         False   \n",
       "1  2025-02-18T13:10:42.128Z               False         False   \n",
       "2  2025-02-18T09:59:34.975Z               False         False   \n",
       "3  2025-02-17T22:32:37.678Z               False         False   \n",
       "4  2025-02-17T22:31:37.158Z               False         False   \n",
       "\n",
       "   UserDef_MR_1_Lb  UserDef_MR_2  UserDef_MR_2_Lb  \n",
       "0              NaN         False              NaN  \n",
       "1              NaN         False              NaN  \n",
       "2              NaN         False              NaN  \n",
       "3              NaN         False              NaN  \n",
       "4              NaN         False              NaN  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets_c_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the datasets\n",
    "merged_data = pd.merge(tickets_c_m, tickets_c_i, on='TicketNumber')\n",
    "merged_data = pd.merge(merged_data, products_s, on='ProductNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DROP BOOLEAN AND NULL COLUMNS (NOT NEEDED) -----\n",
      "\n",
      "Merged Data - Columns to be dropped (Missing Vals): ['BackStage_DefaultReportForm', 'BackStage_SmartMarkSet', 'BillCounty', 'CoreType', 'EndUserNum', 'EndUserPO', 'Equip3_ID', 'Equip3_Status', 'Est_v_Act_Notes', 'Ink_Status', 'JDF_Note_to_DFE', 'JDF_Send_Msg', 'MiscChargeDesc1', 'MiscChargeDesc2', 'MiscChargeDesc3', 'MiscChargeDesc4', 'PlateStat', 'ProofStat', 'Roto_CEL_Product_ID', 'Roto_Quote_Line_ID', 'Roto_Quote_Number', 'Schedule_Status', 'ShipAttn_EmailAddress', 'ShipCounty', 'ShipStat', 'Tag_x', 'Tool3Descr', 'Tool4Descr', 'Tool5Descr', 'ToolNo3', 'ToolNo4', 'ToolNo5', 'ToolStat', 'UserDef_MR_1_Lb', 'UserDef_MR_2_Lb', 'Assigned', 'Desc2_x', 'ediLineNumber', 'eTraxx_Customer_Notes', 'Location_x', 'PO_Number', 'Adhesive', 'Alternate', 'eTraxx_Forecast_Range', 'Material', 'Tag_y', 'UPC']\n",
      "\n",
      "Merged Data - Columns to be dropped (All cols with rows same vals): ['Act_OTHER_Hours', 'ActArtwork', 'ActFinMaterial', 'ActPostPressHours', 'ActualCommissionsCost', 'ActualFanFoldCost', 'ActualFanfoldHours', 'ActualMSI_StockRolls', 'ActualOtherLaborCost', 'ActualPostPressLaborCost', 'ActualTotalPOCosts', 'AmortizePlateChanges', 'Are_Tools_for_Equip', 'Bill_TaxRegion_ID', 'CarrierWidth', 'ColorChangeCost_Extended', 'ColumnPerf', 'CreditHoldOverride', 'Currency_ExchangeRate_x', 'Currency_Rate_ID', 'EarlyShipOK', 'Equip_WashUpHours', 'Equip3_Actual_Cost', 'Equip3_Actual_Hours', 'Equip3_Actual_Length', 'Equip3_Actual_MR_Hours', 'Equip3_Actual_MR_Length', 'Equip3_Actual_Rate', 'Equip3_Actual_Run_Hours', 'Equip3_Actual_Speed', 'Equip3_Actual_WU_Hours', 'Equip3_Done', 'Equip3_EstRunHrs', 'Equip3_EstSpeed', 'Equip3_EstTime', 'Equip3_MakeReadyHours', 'Equip3_NoAcross', 'Equip3_NoAround', 'Equip3_WashUpHours', 'Equip4_Actual_Cost', 'Equip4_Actual_Hours', 'Equip4_Actual_Length', 'Equip4_Actual_MR_Hours', 'Equip4_Actual_MR_Length', 'Equip4_Actual_Run_Hours', 'Equip4_Actual_Speed', 'Equip4_Actual_WU_Hours', 'Equip4_NoAcross', 'Equip4_NoAround', 'Equip4_WashUpHours', 'ESS_Ship', 'ESS_Ship_Sales', 'ESS_TickStat', 'ESS_TickStat_Sales', 'EstArtwork', 'EstPostPressHours', 'EstWuHrs', 'FC_ColorChangeCost', 'FC_ColorChangeCost_Extended', 'FC_Customer_Total', 'FC_EstTotal', 'FC_MiscCharge', 'FC_MiscCharge1', 'FC_MiscCharge2', 'FC_MiscCharge3', 'FC_MiscCharge4', 'FC_PlateChangeCost', 'FC_PlateChangeCost_Extended', 'FC_POTotal', 'FlexPack_Gusset', 'FlexPack_Height', 'FlexPack_LeftTrim', 'FlexPack_RightTrim', 'FlexPack_Type', 'Frames_Lead_Out', 'Is_ActBillNetTax_UserModified', 'Is_AutoOrder', 'LabelsPerFold', 'MiscCharge1', 'MiscCharge2', 'MiscCharge3', 'MiscCharge4', 'POTotal', 'RollLength', 'RowPerf', 'Sheet_Height', 'Sheet_Width', 'Ship_TaxRegion_ID', 'ShipAsOne', 'ShrinkSleeve_CutHeight', 'ShrinkSleeve_LayFlat', 'ShrinkSleeve_OverLap', 'SoldToEndUser', 'StockProdDiscnt', 'StockTicketType', 'SubTicket', 'Tab', 'TabPosition', 'Tape', 'Total_LineWeight', 'TotalOrderWeight', 'TotalShipWeight', 'UserDef_MR_1', 'UserDef_MR_2', 'Art_Item', 'CostM', 'Equip_NoFloods', 'Equip_Null_Cycles', 'Equip3_NoColors', 'Equip3_NoFloods', 'Equip3_Null_Cycles', 'Equip4_NoColors', 'Equip4_NoFloods', 'Equip4_Null_Cycles', 'FC_LineTotal', 'FC_PriceM', 'Line_Weight', 'Plate_Item', 'Press_Null_Cycles', 'Proof_Item', 'Unit_Weight', 'Commission', 'Currency_ExchangeRate_y', 'eTraxx_Forecast_Quantity', 'FC_Cost', 'Inventory_Expires', 'Link_Factor', 'MaxProduce', 'MinProduce', 'Production_Waste', 'Releases_Allowed_Default', 'TotalCost']\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('----- DROP BOOLEAN AND NULL COLUMNS (NOT NEEDED) -----\\n')\n",
    "\n",
    "# drop columns with all rows as missing values (NaN/0)\n",
    "columns_to_drop = merged_data.columns[merged_data.isnull().all()].tolist()\n",
    "print(f'Merged Data - Columns to be dropped (Missing Vals): {columns_to_drop}\\n')\n",
    "merged_data = merged_data.dropna(axis=1, how='all')\n",
    "\n",
    "# set the name attribute for each DataFrame\n",
    "merged_data.name = 'Merged Data'\n",
    "\n",
    "# drop columns with all rows containing the same values of either 0, True, or False\n",
    "for df in [merged_data]:\n",
    "    columns_to_drop = [col for col in df.columns if df[col].nunique() == 1 and df[col].iloc[0] in [0, True, False]]\n",
    "    print(f'{df.name} - Columns to be dropped (All cols with rows same vals): {columns_to_drop}\\n')\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print('-------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped TicQuantity column\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop 'TicQuantity' column as it is for a order (where orders can include multiple products)\n",
    "merged_data.drop(columns='TicQuantity', inplace=True)\n",
    "print('Dropped TicQuantity column\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with 0 values in OrderQuantity column. Rows dropped: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop rows with '0' values in 'OrderQuantity' column\n",
    "merged_data = merged_data[merged_data.OrderQuantity != 0]\n",
    "\n",
    "# display a confirmation message with the rows dropped count\n",
    "print(f'Dropped rows with 0 values in OrderQuantity column. Rows dropped: {len(merged_data[merged_data.OrderQuantity == 0])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- MERGED DATA ----------------\n",
      "   Act_MakeReady_Footage  ActFootage  ActMRHrs  ActPackHrs  ActPressSpd  \\\n",
      "0                      0           0       0.0           0            0   \n",
      "1                      0           0       0.0           0            0   \n",
      "2                      0           0       0.0           0            0   \n",
      "3                      0           0       0.0           0            0   \n",
      "4                      0           0       0.0           0            0   \n",
      "\n",
      "   ActQuantity  ActRunHrs  ActStockCost  ActTotalCost  \\\n",
      "0            0        0.0           0.0        356.25   \n",
      "1            0        0.0           0.0        133.95   \n",
      "2            0        0.0           0.0          5.70   \n",
      "3            0        0.0           0.0          5.00   \n",
      "4            0        0.0           0.0        347.70   \n",
      "\n",
      "   ActualBillings_NetOfSalesTax  ...   ProdSubClass  Product_Image_Size  \\\n",
      "0                           0.0  ...  Self Adhesive                 0.0   \n",
      "1                           0.0  ...  Self Adhesive                 0.0   \n",
      "2                           0.0  ...  Self Adhesive                 0.0   \n",
      "3                           0.0  ...  Self Adhesive                 0.0   \n",
      "4                           0.0  ...  Self Adhesive                 0.0   \n",
      "\n",
      "   Product_UniqueProdID  SupplierName  SupplierNo  SupplierNotes  \\\n",
      "0               22123.0           NaN         NaN            NaN   \n",
      "1               27554.0           NaN         NaN            NaN   \n",
      "2               17798.0           NaN         NaN            NaN   \n",
      "3                2641.0           NaN         NaN            NaN   \n",
      "4               13006.0           NaN         NaN            NaN   \n",
      "\n",
      "   SupplierPartNo   Updated       updateTimeDateStamp  Weight  \n",
      "0             NaN  00/00/00  2025-02-07T16:07:06.894Z       0  \n",
      "1             NaN  00/00/00  2025-02-07T16:07:06.964Z       0  \n",
      "2             NaN  00/00/00  2025-02-17T15:12:34.516Z       0  \n",
      "3             NaN  00/00/00  2025-02-17T09:29:41.571Z       0  \n",
      "4             NaN  00/00/00  2025-02-17T09:29:41.620Z       0  \n",
      "\n",
      "[5 rows x 305 columns]\n",
      "Index(['Act_MakeReady_Footage', 'ActFootage', 'ActMRHrs', 'ActPackHrs',\n",
      "       'ActPressSpd', 'ActQuantity', 'ActRunHrs', 'ActStockCost',\n",
      "       'ActTotalCost', 'ActualBillings_NetOfSalesTax',\n",
      "       ...\n",
      "       'ProdSubClass', 'Product_Image_Size', 'Product_UniqueProdID',\n",
      "       'SupplierName', 'SupplierNo', 'SupplierNotes', 'SupplierPartNo',\n",
      "       'Updated', 'updateTimeDateStamp', 'Weight'],\n",
      "      dtype='object', length=305)\n",
      "-------------------------------------------\n",
      "-------------- SUPPLIER NAMES ----------------\n",
      "['Nilpeter Inc']\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# display merged data after dropping columns\n",
    "print('-------------- MERGED DATA ----------------')\n",
    "print(merged_data.head())\n",
    "# display ALL columns\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Write column names to a text file\n",
    "with open('columns.txt', 'w') as f:\n",
    "    for col in merged_data.columns:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# print all customername and suppliername which arent null in seperate dfs\n",
    "# print('-------------- CUSTOMER NAMES ----------------')\n",
    "# print(merged_data[merged_data.CustomerName.notnull()]['CustomerName'].unique())\n",
    "# print('----------------------------------------------')\n",
    "\n",
    "print('-------------- SUPPLIER NAMES ----------------')\n",
    "print(merged_data[merged_data.SupplierName.notnull()]['SupplierName'].unique())\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_date'] = merged_data['OrderDate']\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['ship_by_date'] = merged_data['Ship_by_Date']\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_month'] = merged_data['order_date'].dt.month\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_week'] = merged_data['order_date'].dt.isocalendar().week\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_year'] = merged_data['order_date'].dt.year\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_weekday'] = merged_data['OrderDate'].dt.weekday\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['is_weekend'] = (merged_data['order_weekday'] >= 5).astype(int)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['quarter'] = merged_data['OrderDate'].dt.quarter\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['is_end_of_month'] = (merged_data['OrderDate'].dt.day > 25).astype(int)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['prev_year_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(12)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['prev_week_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(1)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['yoy_growth'] = (merged_data['OrderQuantity'] - merged_data['prev_year_sales']) / merged_data['prev_year_sales']\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['sales_2022'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2022 else 0, axis=1)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['sales_2023'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2023 else 0, axis=1)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['sales_2024'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2024 else 0, axis=1)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['growth_2023'] = (merged_data['sales_2023'] - merged_data['sales_2022']) / merged_data['sales_2022'] * 100\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['growth_2024'] = (merged_data['sales_2024'] - merged_data['sales_2023']) / merged_data['sales_2023'] * 100\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['prev_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(1)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['prev_2_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(2)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['prev_3_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(3)\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['moving_avg_3m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['moving_avg_6m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=6, min_periods=1).mean())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['moving_avg_12m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=12, min_periods=1).mean())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['moving_avg_18m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=18, min_periods=1).mean())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['var_1m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=1, min_periods=1).var())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['var_3m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=3, min_periods=1).var())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['var_6m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=6, min_periods=1).var())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['var_12m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=12, min_periods=1).var())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['var_18m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=18, min_periods=1).var())\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['log_var_1m'] = np.log1p(merged_data['var_1m'])  # log1p prevents log(0) errors\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['log_var_3m'] = np.log1p(merged_data['var_3m'])\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['log_var_6m'] = np.log1p(merged_data['var_6m'])\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['log_var_12m'] = np.log1p(merged_data['var_12m'])\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['log_var_18m'] = np.log1p(merged_data['var_18m'])\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/423136329.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data[col] = merged_data[col].fillna(merged_data[col].mean())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "TRYING DIFFERENT FEATURES TO SEE HOW THEY ACT WITH MODEL PERFORMANCE\n",
    "'''\n",
    "\n",
    "# ensure date columns are properly formatted\n",
    "merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
    "merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
    "merged_data['order_date'] = merged_data['OrderDate']\n",
    "merged_data['ship_by_date'] = merged_data['Ship_by_Date']\n",
    "\n",
    "# time-based features\n",
    "merged_data['order_month'] = merged_data['order_date'].dt.month\n",
    "merged_data['order_week'] = merged_data['order_date'].dt.isocalendar().week\n",
    "merged_data['order_year'] = merged_data['order_date'].dt.year\n",
    "merged_data['order_weekday'] = merged_data['OrderDate'].dt.weekday\n",
    "merged_data['is_weekend'] = (merged_data['order_weekday'] >= 5).astype(int)\n",
    "merged_data['quarter'] = merged_data['OrderDate'].dt.quarter\n",
    "merged_data['is_end_of_month'] = (merged_data['OrderDate'].dt.day > 25).astype(int)\n",
    "\n",
    "# year-over-year growth (yoy)\n",
    "merged_data['prev_year_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(12)\n",
    "merged_data['prev_week_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(1)\n",
    "merged_data['yoy_growth'] = (merged_data['OrderQuantity'] - merged_data['prev_year_sales']) / merged_data['prev_year_sales']\n",
    "\n",
    "merged_data['sales_2022'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2022 else 0, axis=1)\n",
    "merged_data['sales_2023'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2023 else 0, axis=1)\n",
    "merged_data['sales_2024'] = merged_data.apply(lambda x: x['OrderQuantity'] if x['order_year'] == 2024 else 0, axis=1)\n",
    "\n",
    "# growth of product sales per year (%)\n",
    "merged_data['growth_2023'] = (merged_data['sales_2023'] - merged_data['sales_2022']) / merged_data['sales_2022'] * 100\n",
    "merged_data['growth_2024'] = (merged_data['sales_2024'] - merged_data['sales_2023']) / merged_data['sales_2023'] * 100\n",
    " \n",
    "\n",
    "# lag features (considers past trends via products)\n",
    "merged_data['prev_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(1)\n",
    "merged_data['prev_2_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(2)\n",
    "merged_data['prev_3_month_sales'] = merged_data.groupby('ProductNumber')['OrderQuantity'].shift(3)\n",
    "\n",
    "# time difference features\n",
    "# merged_data['days_since_last_order'] = merged_data.groupby('ProductNumber')['OrderDate'].diff().dt.days.fillna(30)\n",
    "\n",
    "# rolling features\n",
    "merged_data['moving_avg_3m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "merged_data['moving_avg_6m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=6, min_periods=1).mean())\n",
    "merged_data['moving_avg_12m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=12, min_periods=1).mean())\n",
    "merged_data['moving_avg_18m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=18, min_periods=1).mean())\n",
    "\n",
    "merged_data['var_1m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=1, min_periods=1).var())\n",
    "merged_data['var_3m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=3, min_periods=1).var())\n",
    "merged_data['var_6m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=6, min_periods=1).var())\n",
    "merged_data['var_12m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=12, min_periods=1).var())\n",
    "merged_data['var_18m'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: x.rolling(window=18, min_periods=1).var())\n",
    "\n",
    "# log-transformed variance\n",
    "merged_data['log_var_1m'] = np.log1p(merged_data['var_1m'])  # log1p prevents log(0) errors\n",
    "merged_data['log_var_3m'] = np.log1p(merged_data['var_3m'])\n",
    "merged_data['log_var_6m'] = np.log1p(merged_data['var_6m'])\n",
    "merged_data['log_var_12m'] = np.log1p(merged_data['var_12m'])\n",
    "merged_data['log_var_18m'] = np.log1p(merged_data['var_18m'])\n",
    "\n",
    "# check and fill missing values\n",
    "for col in [\n",
    "    'prev_month_sales', 'prev_week_sales', \n",
    "    'moving_avg_3m', 'moving_avg_6m', 'moving_avg_12m', 'moving_avg_18m',\n",
    "    'prev_2_month_sales', 'prev_3_month_sales',\n",
    "    'var_1m', 'var_3m', 'var_6m', 'var_12m', 'var_18m'\n",
    "    ]:\n",
    "    merged_data[col] = merged_data[col].fillna(merged_data[col].mean())\n",
    "\n",
    "# product lifestyle (upcoming, declining, mature) - REDUCES METRICS AND PREDICTION ACCURACIES\n",
    "# merged_data['product_lifecycle'] = merged_data.groupby('ProductNumber')['OrderQuantity'].transform(lambda x: np.where(x.rolling(window=12, min_periods=1).mean() > x.mean(), 'mature', 'new'))\n",
    "\n",
    "# # interaction Features\n",
    "# merged_data['interaction_1'] = merged_data['prev_month_sales'] * merged_data['var_12m']\n",
    "# merged_data['interaction_2'] = merged_data['prev_week_sales'] * merged_data['var_12m']\n",
    "# merged_data['interaction_3'] = merged_data['moving_avg_3m'] * merged_data['moving_avg_12m']\n",
    "# merged_data['interaction_4'] = merged_data['prev_2_month_sales'] * merged_data['var_18m']\n",
    "# merged_data['interaction_5'] = merged_data['prev_3_month_sales'] * merged_data['var_18m']\n",
    "\n",
    "# # demand Factors\n",
    "# merged_data['inventory_ratio'] = merged_data['PhysicalInv'] / (merged_data['OnOrder'] + 1)\n",
    "# merged_data['is_backordered'] = merged_data['BackOrdered'].notna().astype(int)\n",
    "# merged_data['customer_order_count'] = merged_data.groupby('Customer_Num')['OrderQuantity'].transform('count')\n",
    "# merged_data['customer_avg_order'] = merged_data.groupby('Customer_Num')['OrderQuantity'].transform('mean')\n",
    "\n",
    "# aggregation\n",
    "product_sales = merged_data.groupby([ # group rows by:\n",
    "    'ProductNumber', 'order_year', 'order_month', 'order_week',\n",
    "    'Customer_Num'\n",
    "]).agg({ # include these columns with respective data \n",
    "    'OrderQuantity': 'sum', \n",
    "    'prev_month_sales': 'mean',\n",
    "    'prev_week_sales': 'mean',\n",
    "    'prev_2_month_sales': 'mean',\n",
    "    'prev_3_month_sales': 'mean',\n",
    "    'var_1m': 'mean',\n",
    "    'var_3m': 'mean',\n",
    "    'var_6m': 'mean',\n",
    "    'var_12m': 'mean',\n",
    "    'var_18m': 'mean',\n",
    "    'log_var_1m': 'mean',\n",
    "    'log_var_3m': 'mean',\n",
    "    'log_var_6m': 'mean',\n",
    "    'log_var_12m': 'mean',\n",
    "    'log_var_18m': 'mean',\n",
    "    'yoy_growth': 'mean',\n",
    "    'moving_avg_3m': 'mean',\n",
    "    'moving_avg_6m': 'mean',\n",
    "    'moving_avg_12m': 'mean',\n",
    "    'moving_avg_18m': 'mean',\n",
    "    'sales_2022': 'sum',\n",
    "    'sales_2023': 'sum',\n",
    "    'sales_2024': 'sum',\n",
    "    'growth_2023': 'mean',\n",
    "    'growth_2024': 'mean',\n",
    "    }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/1541869033.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_data = merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'])\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_43278/1541869033.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'])\n"
     ]
    }
   ],
   "source": [
    "# add the more feature columns to the product_sales dataset\n",
    "product_sales = pd.merge(product_sales, products_s[['ProductNumber', 'PhysicalInv']], on='ProductNumber')\n",
    "\n",
    "# sales data for SARIMAX time series model test\n",
    "# sales_data = merged_data.groupby(['OrderDate'])['OrderQuantity'].sum()\n",
    "\n",
    "sales_data = merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'])\n",
    "\n",
    "# 'OrderDate' to datetime\n",
    "merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'])\n",
    "\n",
    "# index correctly\n",
    "sales_data = merged_data.set_index(['OrderDate', 'ProductNumber'])\n",
    "sales_data = sales_data['OrderQuantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_week</th>\n",
       "      <th>Customer_Num</th>\n",
       "      <th>OrderQuantity</th>\n",
       "      <th>prev_month_sales</th>\n",
       "      <th>prev_week_sales</th>\n",
       "      <th>prev_2_month_sales</th>\n",
       "      <th>prev_3_month_sales</th>\n",
       "      <th>...</th>\n",
       "      <th>moving_avg_3m</th>\n",
       "      <th>moving_avg_6m</th>\n",
       "      <th>moving_avg_12m</th>\n",
       "      <th>moving_avg_18m</th>\n",
       "      <th>sales_2022</th>\n",
       "      <th>sales_2023</th>\n",
       "      <th>sales_2024</th>\n",
       "      <th>growth_2023</th>\n",
       "      <th>growth_2024</th>\n",
       "      <th>PhysicalInv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFS-005-0002Z</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>7500.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9375.000000</td>\n",
       "      <td>9375.000000</td>\n",
       "      <td>9375.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>9166.666667</td>\n",
       "      <td>9166.666667</td>\n",
       "      <td>9166.666667</td>\n",
       "      <td>9166.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>7500.00000</td>\n",
       "      <td>7500.00000</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>8750.000000</td>\n",
       "      <td>8750.000000</td>\n",
       "      <td>8750.000000</td>\n",
       "      <td>8750.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>196.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFS-005-0003U</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>10833.333333</td>\n",
       "      <td>10833.333333</td>\n",
       "      <td>10833.333333</td>\n",
       "      <td>10833.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFS-005-0003U</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFS-005-0003U</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>196.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFS-005-0003V</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFS-005-0003W</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AFS-005-0003X</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFS-005-0003X</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>196.0</td>\n",
       "      <td>60000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AFS-005-0003Y</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AFS-005-0003Z</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>196.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>40000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>36666.666667</td>\n",
       "      <td>32500.000000</td>\n",
       "      <td>32500.000000</td>\n",
       "      <td>32500.000000</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>33333.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>196.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AFS-005-0005Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>196.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>110031.53337</td>\n",
       "      <td>116746.033342</td>\n",
       "      <td>121992.77576</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AFS-005-0007Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>196.0</td>\n",
       "      <td>60000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>93333.333333</td>\n",
       "      <td>101666.666667</td>\n",
       "      <td>96250.000000</td>\n",
       "      <td>92222.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AFS-005-0007Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>196.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>96041.666667</td>\n",
       "      <td>95000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AFS-005-0007Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>196.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>91458.333333</td>\n",
       "      <td>101111.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AFS-005-0007Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>196.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>104583.333333</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>100588.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AFS-005-0007Y</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>196.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>110000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>110000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>96666.666667</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductNumber  order_year  order_month  order_week  Customer_Num  \\\n",
       "0   AFS-005-0002Z        2022            4          14         196.0   \n",
       "1   AFS-005-0003S        2024            5          20         196.0   \n",
       "2   AFS-005-0003S        2024            9          38         196.0   \n",
       "3   AFS-005-0003S        2024           10          41         196.0   \n",
       "4   AFS-005-0003S        2025            1           5         196.0   \n",
       "5   AFS-005-0003U        2023            9          39         196.0   \n",
       "6   AFS-005-0003U        2023           11          45         196.0   \n",
       "7   AFS-005-0003U        2023           12          52         196.0   \n",
       "8   AFS-005-0003V        2023            8          33         196.0   \n",
       "9   AFS-005-0003W        2023            6          24         196.0   \n",
       "10  AFS-005-0003X        2023            3          12         196.0   \n",
       "11  AFS-005-0003X        2023            6          24         196.0   \n",
       "12  AFS-005-0003Y        2022           12          49         196.0   \n",
       "13  AFS-005-0003Z        2021            9          36         196.0   \n",
       "14  AFS-005-0005Y        2022            8          35         196.0   \n",
       "15  AFS-005-0005Y        2022           11          44         196.0   \n",
       "16  AFS-005-0005Y        2022           12          50         196.0   \n",
       "17  AFS-005-0005Y        2023            1           3         196.0   \n",
       "18  AFS-005-0005Y        2023            2           8         196.0   \n",
       "19  AFS-005-0005Y        2023            4          14         196.0   \n",
       "20  AFS-005-0007Y        2023            4          16         196.0   \n",
       "21  AFS-005-0007Y        2023            6          26         196.0   \n",
       "22  AFS-005-0007Y        2023            8          33         196.0   \n",
       "23  AFS-005-0007Y        2023            9          37         196.0   \n",
       "24  AFS-005-0007Y        2023           10          41         196.0   \n",
       "\n",
       "    OrderQuantity  prev_month_sales  prev_week_sales  prev_2_month_sales  \\\n",
       "0           10000      110031.53337     110031.53337       116746.033342   \n",
       "1           10000       10000.00000      10000.00000        10000.000000   \n",
       "2           10000       10000.00000      10000.00000         7500.000000   \n",
       "3           10000        7500.00000       7500.00000       116746.033342   \n",
       "4            7500      110031.53337     110031.53337       116746.033342   \n",
       "5            2500       10000.00000      10000.00000        20000.000000   \n",
       "6           10000       20000.00000      20000.00000       116746.033342   \n",
       "7           20000      110031.53337     110031.53337       116746.033342   \n",
       "8            2500      110031.53337     110031.53337       116746.033342   \n",
       "9            2500      110031.53337     110031.53337       116746.033342   \n",
       "10          10000       60000.00000      60000.00000       116746.033342   \n",
       "11          60000      110031.53337     110031.53337       116746.033342   \n",
       "12          10000      110031.53337     110031.53337       116746.033342   \n",
       "13          10000      110031.53337     110031.53337       116746.033342   \n",
       "14          40000       30000.00000      30000.00000        30000.000000   \n",
       "15          30000       30000.00000      30000.00000        30000.000000   \n",
       "16          30000       30000.00000      30000.00000        50000.000000   \n",
       "17          30000       50000.00000      50000.00000        20000.000000   \n",
       "18          50000       20000.00000      20000.00000       116746.033342   \n",
       "19          20000      110031.53337     110031.53337       116746.033342   \n",
       "20          60000      110000.00000     110000.00000       110000.000000   \n",
       "21         110000      110000.00000     110000.00000       110000.000000   \n",
       "22         110000      110000.00000     110000.00000       110000.000000   \n",
       "23         110000      110000.00000     110000.00000       110000.000000   \n",
       "24         110000      110000.00000     110000.00000       110000.000000   \n",
       "\n",
       "    prev_3_month_sales  ...  moving_avg_3m  moving_avg_6m  moving_avg_12m  \\\n",
       "0         121992.77576  ...   10000.000000   10000.000000    10000.000000   \n",
       "1           7500.00000  ...   10000.000000    9375.000000     9375.000000   \n",
       "2         121992.77576  ...    9166.666667    9166.666667     9166.666667   \n",
       "3         121992.77576  ...    8750.000000    8750.000000     8750.000000   \n",
       "4         121992.77576  ...    7500.000000    7500.000000     7500.000000   \n",
       "5         121992.77576  ...   10833.333333   10833.333333    10833.333333   \n",
       "6         121992.77576  ...   15000.000000   15000.000000    15000.000000   \n",
       "7         121992.77576  ...   20000.000000   20000.000000    20000.000000   \n",
       "8         121992.77576  ...    2500.000000    2500.000000     2500.000000   \n",
       "9         121992.77576  ...    2500.000000    2500.000000     2500.000000   \n",
       "10        121992.77576  ...   35000.000000   35000.000000    35000.000000   \n",
       "11        121992.77576  ...   60000.000000   60000.000000    60000.000000   \n",
       "12        121992.77576  ...   10000.000000   10000.000000    10000.000000   \n",
       "13        121992.77576  ...   10000.000000   10000.000000    10000.000000   \n",
       "14         30000.00000  ...   33333.333333   33333.333333    33333.333333   \n",
       "15         50000.00000  ...   30000.000000   32000.000000    32000.000000   \n",
       "16         20000.00000  ...   36666.666667   32500.000000    32500.000000   \n",
       "17        121992.77576  ...   33333.333333   33333.333333    33333.333333   \n",
       "18        121992.77576  ...   35000.000000   35000.000000    35000.000000   \n",
       "19        121992.77576  ...   20000.000000   20000.000000    20000.000000   \n",
       "20        110000.00000  ...   93333.333333  101666.666667    96250.000000   \n",
       "21        110000.00000  ...  110000.000000  110000.000000    96041.666667   \n",
       "22        110000.00000  ...  110000.000000  110000.000000    91458.333333   \n",
       "23        110000.00000  ...  110000.000000  104583.333333    87500.000000   \n",
       "24        110000.00000  ...  110000.000000  100000.000000    96666.666667   \n",
       "\n",
       "    moving_avg_18m  sales_2022  sales_2023  sales_2024  growth_2023  \\\n",
       "0     10000.000000       10000           0           0       -100.0   \n",
       "1      9375.000000           0           0       10000          NaN   \n",
       "2      9166.666667           0           0       10000          NaN   \n",
       "3      8750.000000           0           0       10000          NaN   \n",
       "4      7500.000000           0           0           0          NaN   \n",
       "5     10833.333333           0        2500           0          inf   \n",
       "6     15000.000000           0       10000           0          inf   \n",
       "7     20000.000000           0       20000           0          inf   \n",
       "8      2500.000000           0        2500           0          inf   \n",
       "9      2500.000000           0        2500           0          inf   \n",
       "10    35000.000000           0       10000           0          inf   \n",
       "11    60000.000000           0       60000           0          inf   \n",
       "12    10000.000000       10000           0           0       -100.0   \n",
       "13    10000.000000           0           0           0          NaN   \n",
       "14    33333.333333       40000           0           0       -100.0   \n",
       "15    32000.000000       30000           0           0       -100.0   \n",
       "16    32500.000000       30000           0           0       -100.0   \n",
       "17    33333.333333           0       30000           0          inf   \n",
       "18    35000.000000           0       50000           0          inf   \n",
       "19    20000.000000           0       20000           0          inf   \n",
       "20    92222.222222           0       60000           0          inf   \n",
       "21    95000.000000           0      110000           0          inf   \n",
       "22   101111.111111           0      110000           0          inf   \n",
       "23   100588.235294           0      110000           0          inf   \n",
       "24   100000.000000           0      110000           0          inf   \n",
       "\n",
       "    growth_2024  PhysicalInv  \n",
       "0           NaN            0  \n",
       "1           inf         2500  \n",
       "2           inf         2500  \n",
       "3           inf         2500  \n",
       "4           NaN         2500  \n",
       "5        -100.0            0  \n",
       "6        -100.0            0  \n",
       "7        -100.0            0  \n",
       "8        -100.0            0  \n",
       "9        -100.0            0  \n",
       "10       -100.0            0  \n",
       "11       -100.0            0  \n",
       "12          NaN            0  \n",
       "13          NaN            0  \n",
       "14          NaN            0  \n",
       "15          NaN            0  \n",
       "16          NaN            0  \n",
       "17       -100.0            0  \n",
       "18       -100.0            0  \n",
       "19       -100.0            0  \n",
       "20       -100.0         1815  \n",
       "21       -100.0         1815  \n",
       "22       -100.0         1815  \n",
       "23       -100.0         1815  \n",
       "24       -100.0         1815  \n",
       "\n",
       "[25 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_sales.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves outputs of products_sales to '../datasets/stock_forecasting/final'\n",
    "product_sales.to_csv('../datasets/stock_forecasting/final/product_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderDate   ProductNumber\n",
       "2025-02-18  PLA-005-0142Z    338000\n",
       "            PLA-005-0144Y    156000\n",
       "            ODO-032-0067Y     43750\n",
       "2025-02-17  DAK-026-0021Y     12000\n",
       "            DAK-026-0003X     60000\n",
       "Name: OrderQuantity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all columns from all datasets and save them to a txt file (products_s, tickets_c_i, tickets_c_m)\n",
    "# extract columns from each dataset and save them to a txt file one by one\n",
    "columns = pd.DataFrame()\n",
    "\n",
    "# concatenate columns from products_s\n",
    "columns = pd.concat([columns, pd.DataFrame(products_s.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from tickets_c_i\n",
    "columns = pd.concat([columns, pd.DataFrame(tickets_c_i.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from tickets_c_m\n",
    "columns = pd.concat([columns, pd.DataFrame(tickets_c_m.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from sp_inv_adds\n",
    "columns = pd.concat([columns, pd.DataFrame(sp_inv_adds.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from sp_inv_rel\n",
    "columns = pd.concat([columns, pd.DataFrame(sp_inv_rel.columns, columns=['Column'])])\n",
    "\n",
    "# save the columns to a txt file\n",
    "# columns.to_csv('../datasets/stock_forecasting/2022-2025/columns.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
