{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset initialization and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/3694211296.py:4: DtypeWarning: Columns (4,6,20,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  products_s = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Products [STOCK].txt', sep='\\t', header=0) # stock\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/3694211296.py:5: DtypeWarning: Columns (5,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tickets_c_i = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Tickets [CUSTOM] [ITEMS].txt', sep='\\t', header=0) # customer order items\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/3694211296.py:6: DtypeWarning: Columns (43,57,104,139,210,244,251,289,293,310,321,324,326,344,348) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tickets_c_m = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Tickets [CUSTOM] [MAIN].txt', sep='\\t', header=0) # customer order main data\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/3694211296.py:7: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sp_inv_adds = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] SP Inventory [ADDS].txt', sep='\\t', header=0) # customer order main data\n"
     ]
    }
   ],
   "source": [
    "# convert datasets to csv from txt\n",
    "\n",
    "# \\t used as separator, because of raw data format and the headers as row 0\n",
    "products_s = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Products [STOCK].txt', sep='\\t', header=0) # stock\n",
    "tickets_c_i = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Tickets [CUSTOM] [ITEMS].txt', sep='\\t', header=0) # customer order items\n",
    "tickets_c_m = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] Tickets [CUSTOM] [MAIN].txt', sep='\\t', header=0) # customer order main data\n",
    "sp_inv_adds = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] SP Inventory [ADDS].txt', sep='\\t', header=0) # customer order main data\n",
    "sp_inv_rel = pd.read_csv('../datasets/stock_forecasting/2022-2025/[LT] SP Inventory [REL].txt', sep='\\t', header=0) # customer order main data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Product [STOCK] ----------------\n",
      "   Adhesive  Alternate  Available  BackOrdered Box_Size  CaseQty Color  \\\n",
      "0       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "1       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "2       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "3       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "4       NaN        NaN          0            0      NaN      NaN   NaN   \n",
      "\n",
      "   Commission   Cost  Currency_ExchangeRate  ...  SupplierName  SupplierNo  \\\n",
      "0           0   0.00                      0  ...           NaN         NaN   \n",
      "1           0   0.00                      0  ...           NaN         NaN   \n",
      "2           0   0.00                      0  ...           NaN         NaN   \n",
      "3           0   0.00                      0  ...           NaN         NaN   \n",
      "4           0  49.11                      0  ...           NaN         NaN   \n",
      "\n",
      "  SupplierNotes SupplierPartNo Tag TotalCost UPC   Updated  \\\n",
      "0           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "1           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "2           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "3           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "4           NaN            NaN NaN         0 NaN  00/00/00   \n",
      "\n",
      "        updateTimeDateStamp  Weight  \n",
      "0  2024-11-12T18:44:36.831Z       0  \n",
      "1  2024-11-12T18:59:23.570Z       0  \n",
      "2  2024-11-12T18:44:36.849Z       0  \n",
      "3  2024-11-12T18:44:36.879Z       0  \n",
      "4  2024-11-12T18:48:39.525Z       0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "-------------- Tickets [CUSTOM] [ITEMS] ----------------\n",
      "     Art  Art_Item  Art_Ticket  Assigned                        ColorDescr  \\\n",
      "0  False     False       False       NaN         C: WHITE, CMYOK, LAM ADH    \n",
      "1  False     False       False       NaN              C: MYK, GLOSS 54121    \n",
      "2  False     False       False       NaN  C: CMYK,7512C,363C,286C,LAM ADH    \n",
      "3  False     False       False       NaN  C: CMYK,7512C,363C,286C,LAM ADH    \n",
      "4  False     False       False       NaN                C: CMYK, GLOSS V     \n",
      "\n",
      "  ConsecNo  CostM  Desc2                                   Description  \\\n",
      "0      NaN      0    NaN            510016W Gumout All In One FSC 10oz   \n",
      "1      NaN      0    NaN       510022W Gumout Octane Booster 10oz Wrap   \n",
      "2      NaN      0    NaN   Simply Nature 93/7 Ground Beef Famil Pack B   \n",
      "3      NaN      0    NaN  Simply Nature 93/7 Ground Beef Family Pack F   \n",
      "4      NaN      0    NaN      72969 FL Ginger Sweet Chili Sauce 14.5oz   \n",
      "\n",
      "   ediLineNumber  ...  Proof_Out  Proof_Ticket  StckPrdShipStat  \\\n",
      "0            NaN  ...   00/00/00         False              NaN   \n",
      "1            NaN  ...   00/00/00         False              NaN   \n",
      "2            NaN  ...   00/00/00         False              NaN   \n",
      "3            NaN  ...   00/00/00         False              NaN   \n",
      "4            NaN  ...   00/00/00         False              NaN   \n",
      "\n",
      "   StockProductID  TicketNumber  UniquePrice  UniqueProdID  Unit_Weight  \\\n",
      "0             NaN         99999        False       11704.0            0   \n",
      "1             NaN         99997        False        7728.0            0   \n",
      "2             NaN         99996        False       28747.0            0   \n",
      "3             NaN         99995        False       28746.0            0   \n",
      "4             NaN         99993        False       10474.0            0   \n",
      "\n",
      "        updateTimeDateStamp   Work_Status  \n",
      "0  2024-11-07T15:10:02.804Z           NaN  \n",
      "1  2024-11-07T15:03:26.338Z           NaN  \n",
      "2  2024-11-28T15:28:19.649Z  8. In Plates  \n",
      "3  2024-11-13T17:45:49.909Z  8. In Plates  \n",
      "4  2024-11-07T14:38:30.627Z           NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "-------------- Tickets [CUSTOM] [MAIN] ----------------\n",
      "   Act_MakeReady_Footage  Act_OTHER_Hours  ActArtwork  ActFinMaterial  \\\n",
      "0                      0                0           0               0   \n",
      "1                      0                0           0               0   \n",
      "2                      0                0           0               0   \n",
      "3                      0                0           0               0   \n",
      "4                      0                0           0               0   \n",
      "\n",
      "   ActFootage  ActMRHrs  ActPackHrs  ActPostPressHours  ActPressSpd  \\\n",
      "0           0       0.0           0                  0            0   \n",
      "1           0       0.0           0                  0            0   \n",
      "2           0       0.0           0                  0            0   \n",
      "3           0       0.0           0                  0            0   \n",
      "4           0       0.0           0                  0            0   \n",
      "\n",
      "   ActQuantity  ...  TotalOrderWeight  TotalShipWeight  TurnBar     UL  \\\n",
      "0            0  ...                 0                0    False  False   \n",
      "1            0  ...                 0                0    False  False   \n",
      "2            0  ...                 0                0    False  False   \n",
      "3            0  ...                 0                0    False  False   \n",
      "4            0  ...                 0                0    False  False   \n",
      "\n",
      "        updateTimeDateStamp  Use_TurretRewinder  UserDef_MR_1  \\\n",
      "0  2025-01-17T15:28:17.611Z               False         False   \n",
      "1  2025-01-17T15:14:34.082Z               False         False   \n",
      "2  2025-01-17T15:01:30.497Z               False         False   \n",
      "3  2025-01-17T15:00:29.967Z               False         False   \n",
      "4  2025-01-17T14:59:59.708Z               False         False   \n",
      "\n",
      "   UserDef_MR_1_Lb  UserDef_MR_2  UserDef_MR_2_Lb  \n",
      "0              NaN         False              NaN  \n",
      "1              NaN         False              NaN  \n",
      "2              NaN         False              NaN  \n",
      "3              NaN         False              NaN  \n",
      "4              NaN         False              NaN  \n",
      "\n",
      "[5 rows x 365 columns]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# display the first 5 rows of the datasets\n",
    "print('-------------- Product [STOCK] ----------------')\n",
    "print(products_s.head())\n",
    "\n",
    "print('-------------- Tickets [CUSTOM] [ITEMS] ----------------')\n",
    "print(tickets_c_i.head())\n",
    "\n",
    "print('-------------- Tickets [CUSTOM] [MAIN] ----------------')\n",
    "print(tickets_c_m.head())\n",
    "print('------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change product stock column 'ProductNo' to 'ProductNumber' to match the other datasets\n",
    "products_s.rename(columns={'ProductNo': 'ProductNumber'}, inplace=True)\n",
    "\n",
    "# change the column name of 'Number' to 'TicketNumber'\n",
    "tickets_c_m.rename(columns={'Number': 'TicketNumber'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act_MakeReady_Footage</th>\n",
       "      <th>Act_OTHER_Hours</th>\n",
       "      <th>ActArtwork</th>\n",
       "      <th>ActFinMaterial</th>\n",
       "      <th>ActFootage</th>\n",
       "      <th>ActMRHrs</th>\n",
       "      <th>ActPackHrs</th>\n",
       "      <th>ActPostPressHours</th>\n",
       "      <th>ActPressSpd</th>\n",
       "      <th>ActQuantity</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalOrderWeight</th>\n",
       "      <th>TotalShipWeight</th>\n",
       "      <th>TurnBar</th>\n",
       "      <th>UL</th>\n",
       "      <th>updateTimeDateStamp</th>\n",
       "      <th>Use_TurretRewinder</th>\n",
       "      <th>UserDef_MR_1</th>\n",
       "      <th>UserDef_MR_1_Lb</th>\n",
       "      <th>UserDef_MR_2</th>\n",
       "      <th>UserDef_MR_2_Lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-17T15:28:17.611Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-17T15:14:34.082Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-17T15:01:30.497Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-17T15:00:29.967Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-17T14:59:59.708Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Act_MakeReady_Footage  Act_OTHER_Hours  ActArtwork  ActFinMaterial  \\\n",
       "0                      0                0           0               0   \n",
       "1                      0                0           0               0   \n",
       "2                      0                0           0               0   \n",
       "3                      0                0           0               0   \n",
       "4                      0                0           0               0   \n",
       "\n",
       "   ActFootage  ActMRHrs  ActPackHrs  ActPostPressHours  ActPressSpd  \\\n",
       "0           0       0.0           0                  0            0   \n",
       "1           0       0.0           0                  0            0   \n",
       "2           0       0.0           0                  0            0   \n",
       "3           0       0.0           0                  0            0   \n",
       "4           0       0.0           0                  0            0   \n",
       "\n",
       "   ActQuantity  ...  TotalOrderWeight  TotalShipWeight  TurnBar     UL  \\\n",
       "0            0  ...                 0                0    False  False   \n",
       "1            0  ...                 0                0    False  False   \n",
       "2            0  ...                 0                0    False  False   \n",
       "3            0  ...                 0                0    False  False   \n",
       "4            0  ...                 0                0    False  False   \n",
       "\n",
       "        updateTimeDateStamp  Use_TurretRewinder  UserDef_MR_1  \\\n",
       "0  2025-01-17T15:28:17.611Z               False         False   \n",
       "1  2025-01-17T15:14:34.082Z               False         False   \n",
       "2  2025-01-17T15:01:30.497Z               False         False   \n",
       "3  2025-01-17T15:00:29.967Z               False         False   \n",
       "4  2025-01-17T14:59:59.708Z               False         False   \n",
       "\n",
       "   UserDef_MR_1_Lb  UserDef_MR_2  UserDef_MR_2_Lb  \n",
       "0              NaN         False              NaN  \n",
       "1              NaN         False              NaN  \n",
       "2              NaN         False              NaN  \n",
       "3              NaN         False              NaN  \n",
       "4              NaN         False              NaN  \n",
       "\n",
       "[5 rows x 365 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets_c_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the datasets\n",
    "merged_data = pd.merge(tickets_c_m, tickets_c_i, on='TicketNumber')\n",
    "merged_data = pd.merge(merged_data, products_s, on='ProductNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DROP BOOLEAN AND NULL COLUMNS (NOT NEEDED) -----\n",
      "\n",
      "Merged Data - Columns to be dropped (Missing Vals): ['BackStage_DefaultReportForm', 'BackStage_SmartMarkSet', 'BillCounty', 'CoreType', 'EndUserNum', 'EndUserPO', 'Equip3_ID', 'Equip3_Status', 'Equip4_Status', 'Est_v_Act_Notes', 'Freight_AcctNo', 'Ink_Status', 'JDF_Note_to_DFE', 'JDF_Send_Msg', 'MiscChargeDesc1', 'MiscChargeDesc2', 'MiscChargeDesc3', 'MiscChargeDesc4', 'PlateStat', 'ProofStat', 'Roto_CEL_Product_ID', 'Roto_Quote_Line_ID', 'Roto_Quote_Number', 'Schedule_Status', 'ShipAttn_EmailAddress', 'ShipCounty', 'ShipStat', 'Tag_x', 'Tool3Descr', 'Tool4Descr', 'Tool5Descr', 'ToolNo3', 'ToolNo4', 'ToolNo5', 'ToolStat', 'UserDef_MR_1_Lb', 'UserDef_MR_2_Lb', 'Assigned', 'Desc2_x', 'ediLineNumber', 'eTraxx_Customer_Notes', 'Location_x', 'PO_Number', 'Adhesive', 'Alternate', 'Box_Size', 'CaseQty', 'Color', 'eTraxx_Forecast_Range', 'File_Name', 'Material', 'SupplierNotes', 'Tag_y', 'UPC']\n",
      "\n",
      "Merged Data - Columns to be dropped (All cols with rows same vals): ['Act_OTHER_Hours', 'ActArtwork', 'ActFinMaterial', 'ActPostPressHours', 'ActualBillings_NetOfSalesTax', 'ActualCommissionsCost', 'ActualFanFoldCost', 'ActualFanfoldHours', 'ActualGrossMargin_Percent', 'ActualMSI_StockRolls', 'ActualOtherLaborCost', 'ActualPostPressLaborCost', 'ActualTotalPOCosts', 'AmortizeColorChanges', 'AmortizePlateChanges', 'Are_Tools_for_Equip', 'ArtDone', 'Bill_TaxRegion_ID', 'CarrierWidth', 'ColorChangeCost', 'ColorChangeCost_Extended', 'ColumnPerf', 'CreditHoldOverride', 'Currency_ExchangeRate_x', 'Currency_Rate_ID', 'EarlyShipOK', 'Equip_Actual_MR_Length', 'Equip_Actual_WU_Hours', 'Equip_NumUp_Multiplier', 'Equip_WashUpHours', 'Equip3_Actual_Cost', 'Equip3_Actual_Hours', 'Equip3_Actual_Length', 'Equip3_Actual_MR_Hours', 'Equip3_Actual_MR_Length', 'Equip3_Actual_Rate', 'Equip3_Actual_Run_Hours', 'Equip3_Actual_Speed', 'Equip3_Actual_WU_Hours', 'Equip3_Done', 'Equip3_EstRunHrs', 'Equip3_EstSpeed', 'Equip3_EstTime', 'Equip3_MakeReadyHours', 'Equip3_NoAcross', 'Equip3_NoAround', 'Equip3_NumUp_Multiplier', 'Equip3_WashUpHours', 'Equip4_Actual_Cost', 'Equip4_Actual_Hours', 'Equip4_Actual_Length', 'Equip4_Actual_MR_Hours', 'Equip4_Actual_MR_Length', 'Equip4_Actual_Run_Hours', 'Equip4_Actual_Speed', 'Equip4_Actual_WU_Hours', 'Equip4_Done', 'Equip4_NoAcross', 'Equip4_NoAround', 'Equip4_NumUp_Multiplier', 'Equip4_WashUpHours', 'ESC_Art_Sales', 'ESC_Equip', 'ESC_Equip3', 'ESC_Equip3_Sales', 'ESC_Equip4', 'ESC_Equip4_Sales', 'ESC_Finish', 'ESC_Finish_Sales', 'ESC_Ink', 'ESC_Ink_Sales', 'ESC_Plate', 'ESC_Plate_Sales', 'ESC_Press_Sales', 'ESC_Ship_Sales', 'ESC_Stock', 'ESC_Stock_Sales', 'ESC_Tool_Sales', 'ESS_Ship', 'ESS_Ship_Sales', 'ESS_TickStat', 'ESS_TickStat_Sales', 'EstArtwork', 'EstPostPressHours', 'EstWuHrs', 'FC_ColorChangeCost', 'FC_ColorChangeCost_Extended', 'FC_Customer_Total', 'FC_EstTotal', 'FC_MiscCharge', 'FC_MiscCharge1', 'FC_MiscCharge2', 'FC_MiscCharge3', 'FC_MiscCharge4', 'FC_PlateChangeCost', 'FC_PlateChangeCost_Extended', 'FC_POTotal', 'FlexPack_Gusset', 'FlexPack_Height', 'FlexPack_LeftTrim', 'FlexPack_RightTrim', 'FlexPack_Type', 'Frames_Lead_Out', 'Is_ActBillNetTax_UserModified', 'Is_AutoOrder', 'Is_Ink_In', 'LabelsPerFold', 'MiscCharge1', 'MiscCharge2', 'MiscCharge3', 'MiscCharge4', 'NoColorChanges', 'POTotal', 'ProofDone', 'RollLength', 'RowPerf', 'Sheet_Height', 'Sheet_Width', 'Ship_TaxRegion_ID', 'ShipAsOne', 'ShrinkSleeve_CutHeight', 'ShrinkSleeve_LayFlat', 'ShrinkSleeve_OverLap', 'SoldToEndUser', 'StockProdDiscnt', 'StockTicketType', 'SubTicket', 'Tab', 'TabPosition', 'Tape', 'Total_LineWeight', 'TotalOrderWeight', 'TotalShipWeight', 'UserDef_MR_1', 'UserDef_MR_2', 'Art', 'Art_Item', 'Art_Ticket', 'CostM', 'Equip_NoColors', 'Equip_NoFloods', 'Equip_Null_Cycles', 'Equip3_NoColors', 'Equip3_NoFloods', 'Equip3_Null_Cycles', 'Equip4_NoColors', 'Equip4_NoFloods', 'Equip4_Null_Cycles', 'FC_LineTotal', 'FC_PriceM', 'Line_Weight', 'Plate_Item', 'Press_Null_Cycles', 'Proof', 'Proof_Item', 'Proof_Ticket', 'Unit_Weight', 'Commission', 'Currency_ExchangeRate_y', 'eTraxx_Forecast_Quantity', 'FC_Cost', 'InternetQuery', 'Inventory_Expires', 'Link_Factor', 'MaxProduce', 'MinProduce', 'Product_Image_Size', 'Production_Waste', 'Releases_Allowed_Default', 'TotalCost', 'Weight']\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('----- DROP BOOLEAN AND NULL COLUMNS (NOT NEEDED) -----\\n')\n",
    "\n",
    "# drop columns with all rows as missing values (NaN/0)\n",
    "columns_to_drop = merged_data.columns[merged_data.isnull().all()].tolist()\n",
    "print(f'Merged Data - Columns to be dropped (Missing Vals): {columns_to_drop}\\n')\n",
    "merged_data = merged_data.dropna(axis=1, how='all')\n",
    "\n",
    "# set the name attribute for each DataFrame\n",
    "merged_data.name = 'Merged Data'\n",
    "\n",
    "# drop columns with all rows containing the same values of either 0, True, or False\n",
    "for df in [merged_data]:\n",
    "    columns_to_drop = [col for col in df.columns if df[col].nunique() == 1 and df[col].iloc[0] in [0, True, False]]\n",
    "    print(f'{df.name} - Columns to be dropped (All cols with rows same vals): {columns_to_drop}\\n')\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print('-------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped TicQuantity column\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop 'TicQuantity' column as it is for a order (where orders can include multiple products)\n",
    "merged_data.drop(columns='TicQuantity', inplace=True)\n",
    "print('Dropped TicQuantity column\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with 0 values in OrderQuantity column. Rows dropped: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop rows with '0' values in 'OrderQuantity' column\n",
    "merged_data = merged_data[merged_data.OrderQuantity != 0]\n",
    "\n",
    "# display a confirmation message with the rows dropped count\n",
    "print(f'Dropped rows with 0 values in OrderQuantity column. Rows dropped: {len(merged_data[merged_data.OrderQuantity == 0])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- MERGED DATA ----------------\n",
      "   Act_MakeReady_Footage  ActFootage  ActMRHrs  ActPackHrs  ActPressSpd  \\\n",
      "0                      0           0       0.0           0            0   \n",
      "1                      0           0       0.0           0            0   \n",
      "2                      0           0       0.0           0            0   \n",
      "3                      0           0       0.0           0            0   \n",
      "4                      0           0       0.0           0            0   \n",
      "\n",
      "   ActQuantity  ActRunHrs  ActStockCost  ActTotalCost  ActualFanfoldRate  ...  \\\n",
      "0            0        0.0           0.0           0.0                  0  ...   \n",
      "1            0        0.0           0.0           0.0                  0  ...   \n",
      "2            0        0.0           0.0           0.0                  0  ...   \n",
      "3            0        0.0           0.0          17.5                  0  ...   \n",
      "4            0        0.0           0.0           0.0                  0  ...   \n",
      "\n",
      "   PriceMode  PriceMode_Local_y             ProdClass   ProdSubClass  \\\n",
      "0      Per M              Per M    Country Pure Foods  Self Adhesive   \n",
      "1      Per M              Per M    Country Pure Foods  Self Adhesive   \n",
      "2      Per M              Per M    Country Pure Foods  Self Adhesive   \n",
      "3      Per M              Per M  Swift Prepared Foods  Self Adhesive   \n",
      "4      Per M              Per M    Uncle John's Pride  Self Adhesive   \n",
      "\n",
      "   Product_UniqueProdID  SupplierName  SupplierNo  SupplierPartNo   Updated  \\\n",
      "0               12822.0           NaN         NaN             NaN  00/00/00   \n",
      "1               27339.0           NaN         NaN             NaN  00/00/00   \n",
      "2               20161.0           NaN         NaN             NaN  00/00/00   \n",
      "3               21779.0           NaN         NaN             NaN  00/00/00   \n",
      "4               25542.0           NaN         NaN             NaN  00/00/00   \n",
      "\n",
      "        updateTimeDateStamp  \n",
      "0  2025-01-17T13:46:01.549Z  \n",
      "1  2025-01-17T13:46:03.637Z  \n",
      "2  2025-01-17T13:46:03.095Z  \n",
      "3  2025-01-17T14:53:02.886Z  \n",
      "4  2025-01-17T13:34:30.547Z  \n",
      "\n",
      "[5 rows x 253 columns]\n",
      "Index(['Act_MakeReady_Footage', 'ActFootage', 'ActMRHrs', 'ActPackHrs',\n",
      "       'ActPressSpd', 'ActQuantity', 'ActRunHrs', 'ActStockCost',\n",
      "       'ActTotalCost', 'ActualFanfoldRate',\n",
      "       ...\n",
      "       'PriceMode', 'PriceMode_Local_y', 'ProdClass', 'ProdSubClass',\n",
      "       'Product_UniqueProdID', 'SupplierName', 'SupplierNo', 'SupplierPartNo',\n",
      "       'Updated', 'updateTimeDateStamp'],\n",
      "      dtype='object', length=253)\n",
      "-------------------------------------------\n",
      "-------------- SUPPLIER NAMES ----------------\n",
      "['Nilpeter Inc']\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# display merged data after dropping columns\n",
    "print('-------------- MERGED DATA ----------------')\n",
    "print(merged_data.head())\n",
    "# display ALL columns\n",
    "print(merged_data.columns)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# print all customername and suppliername which arent null in seperate dfs\n",
    "# print('-------------- CUSTOMER NAMES ----------------')\n",
    "# print(merged_data[merged_data.CustomerName.notnull()]['CustomerName'].unique())\n",
    "# print('----------------------------------------------')\n",
    "\n",
    "print('-------------- SUPPLIER NAMES ----------------')\n",
    "print(merged_data[merged_data.SupplierName.notnull()]['SupplierName'].unique())\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_date'] = merged_data['OrderDate']\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['ship_by_date'] = merged_data['Ship_by_Date']\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_month'] = merged_data['order_date'].dt.month\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_week'] = merged_data['order_date'].dt.isocalendar().week\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_year'] = merged_data['order_date'].dt.year\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['order_weekday'] = merged_data['OrderDate'].dt.weekday  # Monday = 0, Sunday = 6\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['is_weekend'] = (merged_data['order_weekday'] >= 5).astype(int)  # 1 for Sat/Sun\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['inventory_ratio'] = merged_data['PhysicalInv'] / (merged_data['OnOrder'] + 1)  # Avoid division by zero\n",
      "/var/folders/31/9bd8ksys1rzbjk8qs9scl95h0000gn/T/ipykernel_5583/694328055.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data['is_backordered'] = merged_data['BackOrdered'].notna().astype(int)\n"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
    "merged_data['Ship_by_Date'] = pd.to_datetime(merged_data['Ship_by_Date'], errors='coerce')\n",
    "merged_data['order_date'] = merged_data['OrderDate']\n",
    "merged_data['ship_by_date'] = merged_data['Ship_by_Date']\n",
    "merged_data['order_month'] = merged_data['order_date'].dt.month\n",
    "merged_data['order_week'] = merged_data['order_date'].dt.isocalendar().week\n",
    "merged_data['order_year'] = merged_data['order_date'].dt.year\n",
    "merged_data['order_weekday'] = merged_data['OrderDate'].dt.weekday  # Monday = 0, Sunday = 6\n",
    "merged_data['is_weekend'] = (merged_data['order_weekday'] >= 5).astype(int)  # 1 for Sat/Sun\n",
    "\n",
    "\n",
    "# Additional demand factors\n",
    "merged_data['inventory_ratio'] = merged_data['PhysicalInv'] / (merged_data['OnOrder'] + 1)  # Avoid division by zero\n",
    "merged_data['is_backordered'] = merged_data['BackOrdered'].notna().astype(int)\n",
    "\n",
    "# aggregate the data\n",
    "product_sales = merged_data.groupby(['ProductNumber', 'order_year', 'order_month', 'order_week', 'Customer_Num','order_weekday', 'is_weekend', 'inventory_ratio', 'is_backordered']).agg({'OrderQuantity': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the more feature columns to the product_sales dataset\n",
    "product_sales = pd.merge(product_sales, products_s[['ProductNumber', 'PhysicalInv']], on='ProductNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_week</th>\n",
       "      <th>Customer_Num</th>\n",
       "      <th>order_weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>inventory_ratio</th>\n",
       "      <th>is_backordered</th>\n",
       "      <th>OrderQuantity</th>\n",
       "      <th>PhysicalInv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFS-005-0003S</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>196.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFS-005-0003U</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFS-005-0003U</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>196.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductNumber  order_year  order_month  order_week  Customer_Num  \\\n",
       "0  AFS-005-0003S        2024            5          20         196.0   \n",
       "1  AFS-005-0003S        2024            9          38         196.0   \n",
       "2  AFS-005-0003S        2024           10          41         196.0   \n",
       "3  AFS-005-0003U        2023            9          39         196.0   \n",
       "4  AFS-005-0003U        2023           11          45         196.0   \n",
       "\n",
       "   order_weekday  is_weekend  inventory_ratio  is_backordered  OrderQuantity  \\\n",
       "0              1           0              0.0               1          10000   \n",
       "1              4           0              0.0               1          10000   \n",
       "2              3           0              0.0               1          10000   \n",
       "3              4           0              0.0               1           2500   \n",
       "4              3           0              0.0               1          10000   \n",
       "\n",
       "   PhysicalInv  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all columns from all datasets and save them to a txt file (products_s, tickets_c_i, tickets_c_m)\n",
    "# extract columns from each dataset and save them to a txt file one by one\n",
    "columns = pd.DataFrame()\n",
    "\n",
    "# concatenate columns from products_s\n",
    "columns = pd.concat([columns, pd.DataFrame(products_s.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from tickets_c_i\n",
    "columns = pd.concat([columns, pd.DataFrame(tickets_c_i.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from tickets_c_m\n",
    "columns = pd.concat([columns, pd.DataFrame(tickets_c_m.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from sp_inv_adds\n",
    "columns = pd.concat([columns, pd.DataFrame(sp_inv_adds.columns, columns=['Column'])])\n",
    "\n",
    "# concatenate columns from sp_inv_rel\n",
    "columns = pd.concat([columns, pd.DataFrame(sp_inv_rel.columns, columns=['Column'])])\n",
    "\n",
    "# save the columns to a txt file\n",
    "# columns.to_csv('../datasets/stock_forecasting/2022-2025/columns.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
